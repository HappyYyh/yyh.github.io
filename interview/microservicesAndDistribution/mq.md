---
title: MQ
permalink: /interview/microservicesAndDistribution/mq
key: microservicesAndDistribution-mq
---



## 消费

### 【消息队列简介、用途】

**简介：**

> “消息队列”是在消息的传输过程中保存消息的容器。   ——[百度百科](https://baike.baidu.com/item/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/4751675?fr=aladdin)

**用途：**

- 解耦

  允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

- 异步

  很多时候，用户不想也不需要立即处理消息。比如发红包，发短信等流程。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们

- 削峰

  使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。



### 【消息的推拉模型】

**Push 和 Pull的概念**

- 所谓 Push 模型，即当 Producer 发出的消息到达后，服务端马上将这条消息投递给 Consumer；
- 而 Pull 则是服务端收到这条消息后什么也不做，只是等着 Consumer 主动到自己这里来读，即 Consumer 这里有一个“拉取”的动作。

**Push模型优缺点**

- Push模型优点

  实时（因为服务端Broker一旦收到消息，就会发送给消费者，不管消费这准备好没有，消费者是死是活，缓存到消费端的BlockingQueue中）

- Push缺点

  1. 消息保存在服务端broker，容易造成消息堆积。

  2. 服务端broker需要维护每次传输状态，遇到问题需要重试

  3. 服务端broker需要依据订阅者消费能力做流控(流转机制)。

**Pull模型优缺点**

- Pull模型优点
  1. 保存在消费端，获取消息方便。

  2. 传输失败，不需要重试。

  3. 消费端可以根据自身消费能力决定是否pull(流转机制) 

- Pull缺点

  默认的短轮询方式的实时性依赖于pull间隔时间，间隔越大，实时性越低，长轮询方式和push一致。

**各消息中间件推拉支持**

|  中间件  | push模型 |   pull模型   |
| :------: | :------: | :----------: |
| RabbitMQ |   支持   |     支持     |
|  Kafka   |   ---    | 支持（只有） |
| RocketMQ |   支持   |     支持     |



### 【消息主动推送怎么实现】

​	可以结合websocket或者stom协议实现消息的主动推送



### 【消息如何保证一定被消费，如何没有消费到怎么办】

以RabbitMQ为例，可以使用消息持久化+ACK（消息确认机制）

**流程：**

1. 订单服务生产者再投递消息之前，先把消息持久化到Redis或DB中，建议redis，高性能。消息的状态为发送中。
2. confirm机制监听消息是否发送成功？如ack成功消息，删除redis中此消息。
3. 如果nack不成功的消息，这个可以根据自身的业务选择是否重发此消息。也可以删除此消息，由自己的业务决定。
4. 这边加了个定时任务，来拉取隔一定时间了，消息状态还是为发送中的，这个状态就表明，订单服务是没有收到ack成功消息。
5. 定时任务会作补偿性的投递消息。这个时候如果MQ回调ack成功接收了，再把redis中此消息删除



**处理失败消息：死信队列**

一般生产环境中，如果你有丰富的架构设计经验，都会在使用MQ的时候设计两个队列：一个是**核心业务队列**，一个是**死信队列**。

- 核心业务队列就是用来业务逻辑的。
- 死信队列就是用来处理异常情况的。

比如说要是第三方物流系统故障了，此时无法请求，那么仓储系统每次消费到一条订单消息，尝试通知发货和配送，都会遇到对方的接口报错。此时仓储系统就可以把这条消息拒绝访问，或者标志位处理失败！注意，这个步骤很重要。一旦标志这条消息处理失败了之后，MQ就会把这条消息转入提前设置好的一个死信队列中。然后你会看到的就是，在第三方物流系统故障期间，所有订单消息全部处理失败，全部会转入死信队列。然后你的仓储系统得专门有一个后台线程，监控第三方物流系统是否正常，能否请求的，不停的监视。一旦发现对方恢复正常，这个后台线程就从死信队列消费出来处理失败的订单，重新执行发货和配送的通知逻辑。

死信队列的使用，其实就是MQ在生产实践中非常重要的一环，也就是架构设计必须要考虑的。



### 【如何保证消息不被重复消费（消息幂等）】

> 幂等性是指一个请求，不管重复来多少次，结果是不会改变的。

消息被重复消费可能造成数据库插入多条相同的记录等坏情况，解决方法得结合实际业务情况来看：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。



### 【MQ的可靠性怎么保证（处理消息丢失）】 

以RabbitMQ为例：

**生产者防止数据丢失**

生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢了，因为网络问题啥的，都有可能。

- **解决方案一：**

  用 RabbitMQ 提供的事务功能，就是生产者**发送数据之前**开启 RabbitMQ 事务`channel.txSelect`，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务`channel.txRollback`，然后重试发送消息；如果收到了消息，那么可以提交事务`channel.txCommit`。

  ```java
  // 开启事务
  channel.txSelect
  try {
      // 这里发送消息
  } catch (Exception e) {
      channel.txRollback
  
      // 这里再次重发这条消息
  }
  
  // 提交事务
  channel.txCommit
  ```

- **解决方案二：**

  但是问题是，RabbitMQ 事务机制（同步）一搞，基本上**吞吐量会下来，因为太耗性能**。

  所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

  事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。

  所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。

**消息队列防止数据丢失**

​	 RabbitMQ 自己弄丢了数据，这个你必须**开启 RabbitMQ 的持久化**，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。

**消费端防止数据丢失**

​	消费者消费的时候，**刚消费到，还没处理，结果进程挂了**，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。

​	这个时候得用 RabbitMQ 提供的 `ack` 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 `ack`，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 `ack` 一把。这样的话，如果你还没处理完，不就没有 `ack` 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。



### 【消息队列消费积压如何解决】  

**问题由来：**

消费端出了问题，不消费了；或者消费的速度极其慢，这回会导致消息积压

一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。



### 【MQ对比】

|           特性           |               ActiveMQ                |                      RabbitMQ                      |                           RocketMQ                           |                            Kafka                             |
| :----------------------: | :-----------------------------------: | :------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|        单机吞吐量        | 万级，比 RocketMQ、Kafka 低一个数量级 |                    同 ActiveMQ                     |                     10 万级，支撑高吞吐                      | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
|          时效性          |                 ms 级                 |     微秒级，这是 RabbitMQ 的一大特点，延迟最低     |                            ms 级                             |                       延迟在 ms 级以内                       |
|          可用性          |      高，基于主从架构实现高可用       |                    同 ActiveMQ                     |                      非常高，分布式架构                      | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
|        消息可靠性        |         有较低的概率丢失数据          |                      基本不丢                      |              经过参数优化配置，可以做到 0 丢失               |                         同 RocketMQ                          |
|         功能支持         |         MQ 领域的功能极其完备         | 基于 erlang 开发，并发能力很强，性能极好，延时很低 |           MQ 功能较为完善，还是分布式的，扩展性好            | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |



## Kafka

kafka有哪些组件  
kafka两种消费模式  
kafka怎么做有序消费  
kafka的作用和架构  
kafka 最早是为了解决什么问题设计的  
kafka 网络中有哪些组件，为什么kafka 用zookeeper来存储metadata，而不是用db来存储  
Kafka局部有序  
kafka的replicas的作用，为什么比其他的消息队列好。  
kafka中patiton如何保证有序  
kafka 只有一次生产 只有一次消费怎么做  
kafka如何保证不丢消息又不会重复消费。  
kafka一致性  
kafka相对于其他的优点   
kafka 重消费解决  
kafka如何保证可靠，高可用，幂等
假设公司有上万人，一则通知要快速的推送到每个人，如何通过kafka来实现 ?  



## RabbitMQ

对rabbitmq了解哪些？   
rabbitmq消息队列如何解决消息丢失  
rabbitmq和其他消息队列的对比   
rabbitmq能避免发送重复数据吗？  
rabbitmq的可靠性如何保证 ？  



## RocketMQ

RocketMQ的commitLog的作用    
为什么commitLog每个文件的大小是1G？   



【nameServer的作用】 

【nameServer所有的节点数据是一致的吗】